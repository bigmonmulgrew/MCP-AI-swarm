services:
  ollama:
    image: ollama/ollama:latest
    container_name: ollama-container
    ports:
      - "${OLLAMA_PORT_E:-11434}:${OLLAMA_PORT_I:-11434}"
    volumes:
      - ${OLLAMA_MODEL_STORAGE:-./ollama-data}:/var/lib/ollama
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    runtime: nvidia

  aiqueue:
    build:
      context: .
      dockerfile: ./AIqueue/Dockerfile
    container_name: ai-queue
    ports:
      - "${AI_QUEUE_PORT_E:-9090}:${AI_QUEUE_PORT_I:-9090}"
    environment:
      - OLLAMA_URL=http://${OLLAMA_HOST:-ollama}:${OLLAMA_PORT_E:-11434}
      - OLLAMA_DEFAULT_MODEL="${OLLAMA_DEFAULT_MODEL:-llama3.2}"
      - AI_MAX_CONCURRENT="${AI_MAX_CONCURRENT:-1}"

    volumes:
      - ./AIqueue:/app   # live code mounting for dev
    depends_on:
      - ollama
    restart: unless-stopped

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: frontend-container
    ports:
      - "${FRONTEND_PORT_E:-5173}:${FRONTEND_PORT_I:-5173}"
    environment:
      - API_URL=http://${MCPS_HOST:-mcps}:${MCPS_PORT_I:-8080}
      - MCP_VISUALISER_URL=http://${MCP_VISUALISER_HOST:-mcp-visualiser}:${MCP_VISUALISER_PORT_I:-8070}
      - MCP_DATA_URL=http://${MCP_DATA_HOST:-mcp-data}:${MCP_DATA_PORT_I:-8060}
      - MCPS_HOST=${MCPS_HOST:-127.0.0.1}
      - MCPS_PORT=${MCPS_PORT_I:-8080}
    depends_on:
      - mcps
    restart: unless-stopped

  mcps:
    build:
      context: .
      dockerfile: ./mcps/Dockerfile
    container_name: mcps-container
    ports:
      - "${MCPS_PORT_E:-8080}:${MCPS_PORT_I:-8080}"
    environment:
      - OLLAMA_URL=http://${OLLAMA_HOST:-ollama}:${OLLAMA_PORT_E:-11434}
      - AI_QUEUE_URL=http://${AI_QUEUE_HOST:-ai-queue}:${AI_QUEUE_PORT_E:-9090}
      - MCP_DATA_URL=http://${MCP_DATA_HOST:-mcp-data}:${MCP_DATA_PORT_E:-8060}
      - MCP_VISUALISER_URL=http://${MCP_VISUALISER_HOST:-mcp-data}:${MCP_VISUALISER_PORT_E:-8060}
    volumes:
      - ./mcps:/app   # live code mounting for dev
    depends_on:
      - aiqueue
    restart: unless-stopped

  mcp-visualiser:
    build:
      context: .
      dockerfile: ./MCP-Visualiser/Dockerfile
    container_name: mcp-visualiser-container
    ports:
      - "${MCP_VISUALISER_PORT_E:-8070}:${MCP_VISUALISER_PORT_I:-8070}"
    environment:
      - OLLAMA_URL=http://${OLLAMA_HOST:-ollama}:${OLLAMA_PORT_E:-11434}
      - MCP_DATA_URL=http://${MCP_DATA_HOST:-mcp-data}:${MCP_DATA_PORT_E:-8060}
      - MCPS_HOST=${MCPS_HOST:-127.0.0.1}
      - MCPS_PORT=${MCPS_PORT_I:-8080}
    volumes:
      - ./MCP-Visualiser:/app    # live code mounting for dev
    depends_on:
      - ollama
    restart: unless-stopped

  mcp-data:
    build:
      context: .
      dockerfile: ./MCP-Data/Dockerfile
    container_name: mcp-data-container
    ports:
      - "${MCP_DATA_PORT_E:-8060}:${MCP_DATA_PORT_I:-8060}"
    environment:
      - OLLAMA_URL=http://${OLLAMA_HOST:-ollama}:${OLLAMA_PORT_E:-11434}
      - MCPS_HOST=${MCPS_HOST:-127.0.0.1}
      - MCPS_PORT=${MCPS_PORT_I:-8080}
    volumes:
      - ./MCP-Data:/app    # live code mounting for dev
    depends_on:
      - ollama
    restart: unless-stopped
