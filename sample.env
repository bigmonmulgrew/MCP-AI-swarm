# External storage settings.
# Local AI model storage Default is inside repo
OLLAMA_MODEL_STORAGE="./ollama-data"

# Ollama 
OLLAMA_PORT_E=11434
OLLAMA_PORT_I=11434
OLLAMA_HOST=ollama


# AI queue
AI_QUEUE_PORT_E=9090
AI_QUEUE_PORT_I=9090
AI_QUEUE_HOST=ai-queue
OLLAMA_DEFAULT_MODEL=llama3.2
AI_MAX_CONCURRENT=1             # Warning, setting too high can cause performance issues

# Frontend
FRONTEND_PORT_E=5173
FRONTEND_PORT_I=5173

# Multi Context Protocol Server (MCPS)
MCPS_PORT_E=8080
MCPS_PORT_I=8080
MCPS_HOST=mcps

# MCP Visualiser
MCP_VISUALISER_PORT_E=8070
MCP_VISUALISER_PORT_I=8070
MCP_VISUALISER_HOST=mcp-visualiser
 
# MCP Data
MCP_DATA_PORT_E=8060
MCP_DATA_PORT_I=8060
MCP_DATA_HOST=mcp-data