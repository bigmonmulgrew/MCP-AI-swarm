# External storage settings.

# Local AI model storage Default is inside repo
OLLAMA_MODEL_STORAGE="./ollama_models"

# Ollama 
OLLAMA_PORT_E=11434
OLLAMA_PORT_I=11434
OLLAMA_HOST=ollama

# AI queue
AI_QUEUE_PORT_E=9090
AI_QUEUE_PORT_I=9090
AI_QUEUE_HOST=ai-queue
AI_MAX_CONCURRENT=1             # Warning, setting too high can cause performance issues

# Ollama Settings
OLLAMA_DEFAULT_MODEL=llama3.2
OLLAMA_DEFAULT_TEMP=0.0
OLLAMA_MAX_TOKENS=10000
OLLAMA_TIMEOUT=300
 
# Frontend
FRONTEND_PORT_E=5173
FRONTEND_PORT_I=5173

# Multi Context Protocol Server (MCPS)
MCPS_PORT_E=8080
MCPS_PORT_I=8080
MCPS_HOST=mcps

# MCP Visualiser
MCP_VISUALISER_PORT_E=8070
MCP_VISUALISER_PORT_I=8070
MCP_VISUALISER_HOST=mcp-visualiser
 
# MCP Data
MCP_DATA_PORT_E=8060
MCP_DATA_PORT_I=8060
MCP_DATA_HOST=mcp-data

MCP_VERDICT_PORT_E=8050
MCP_VERDICT_PORT_I=8050
MCP_VERDICT_HOST=mcp-verdict
